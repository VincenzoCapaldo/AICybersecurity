{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 0. Variabili globali e funzioni di utils (da eseguire ogni volta)",
   "id": "e71d5996b80309c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:57:00.847030Z",
     "start_time": "2025-04-16T10:56:55.352032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from facenet_pytorch.models.inception_resnet_v1 import InceptionResnetV1\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# pre-processa le immagini in modo compatibile con la rete.\n",
    "def load_images(filepath):\n",
    "    img = Image.open(filepath).convert(\"RGB\")\n",
    "    rsz = img.resize((160, 160))\n",
    "    tns = transforms.ToTensor()(rsz)\n",
    "    return tns, rsz\n",
    "\n",
    "\n",
    "def evaluate_performance(device, net, test_set=\".\\\\dataset\\\\test_set\", labels=\".\\\\dataset\\\\test_set.csv\"):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    LABELS = np.load(\".\\\\dataset\\\\rcmalli_vggface_labels_v2.npy\")\n",
    "    true_labels = {str(name).strip(): idx for idx, name in enumerate(LABELS)}\n",
    "\n",
    "    with open(labels, \"r\", encoding=\"utf-8\") as csvfile: # apri con la codifica corretta.\n",
    "        reader = csv.reader(csvfile)\n",
    "\n",
    "        for row in reader:\n",
    "            filename, name = row[0], row[1].strip(' \"') # togli spazio e doppi apici.\n",
    "            img_path = os.path.join(test_set, filename)\n",
    "            for img in os.listdir(img_path):\n",
    "                try:\n",
    "                    img_tensor, _ = load_images(img_path + \"/\" + img) # usa il path completo.\n",
    "                except Exception as e:\n",
    "                    print(f\"Errore nel caricamento di {img_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                img_tensor = img_tensor.unsqueeze(0)  # aggiunge dimensione batch.\n",
    "                with torch.no_grad():\n",
    "                    output = net(img_tensor.to(device))\n",
    "                    # dato l'output ottieni la stringa corrispondente.\n",
    "                    predicted_class = np.array(output[0].detach().cpu().numpy()).argmax()\n",
    "\n",
    "                y_true.append(true_labels[name])\n",
    "                y_pred.append(predicted_class)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "NN1 = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "NN1.to(device)\n",
    "NN1.classify = True\n",
    "print(\"Modello NN1 caricato correttamente\")"
   ],
   "id": "bd52949e3466dc8b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\39331\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: DLL load failed while importing _multiarray_umath: Impossibile trovare il modulo specificato. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "C:\\Users\\39331\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Modello NN1 caricato correttamente\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Creazione del test set\n",
   "id": "c69de60491c1c74b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Parametri\n",
    "csv_file = '.\\\\dataset\\\\test_set.csv' # Percorso al file CSV contenente gli ID delle persone da inserire nel dataset finale (es. 'n000016'). Ogni riga deve contenere almeno un ID\n",
    "dataset_directory_origin = '.\\\\dataset\\\\vggface2_train\\\\train' # Directory di origine contenente le sottocartelle per ogni ID persona con le immagini\n",
    "dataset_directory_destination = '.\\\\dataset\\\\test_set' # Directory in cui salvare le immagini selezionate\n",
    "number_img = 10 # Numero massimo di immagini da copiare per ciascun ID\n",
    "\n",
    "# Lettura del file CSV contenente gli ID delle persone\n",
    "with open(csv_file, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')  # i campi sono separati da virgole\n",
    "\n",
    "    for row in reader:\n",
    "        if len(row) < 1:\n",
    "            continue  # salta righe vuote\n",
    "\n",
    "        person_id = row[0].strip()  # es: \"n000016\"\n",
    "\n",
    "        # Costruzione dei percorsi di origine e destinazione per ogni persona\n",
    "        origin_path = os.path.join(dataset_directory_origin, person_id)\n",
    "        destination_path = os.path.join(dataset_directory_destination, person_id)\n",
    "\n",
    "        if not os.path.exists(origin_path):\n",
    "            print(f\"Cartella non trovata: {origin_path}\")\n",
    "            continue\n",
    "\n",
    "        # Lista dei file immagine nella cartella della persona\n",
    "        images = [f for f in os.listdir(origin_path) if os.path.isfile(os.path.join(origin_path, f))]\n",
    "        if not images:\n",
    "            print(f\"Nessuna immagine in: {origin_path}\")\n",
    "            continue\n",
    "\n",
    "        # Seleziona un numero massimo di immagini in modo casuale\n",
    "        selected_images = random.sample(images, min(number_img, len(images)))\n",
    "\n",
    "        # Crea la cartella di destinazione se non esiste\n",
    "        os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "        # Copia e rinomina le immagini nella cartella di destinazione\n",
    "        for idx, image in enumerate(selected_images):\n",
    "            src = os.path.join(origin_path, image)\n",
    "            ext = os.path.splitext(image)[1]  # estensione del file (es. .jpg)\n",
    "            dst_filename = f\"{person_id}_{idx + 1:02d}{ext}\"  # es: n000016_01.jpg\n",
    "            dst = os.path.join(destination_path, dst_filename)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "        print(f\"Copiate {len(selected_images)} immagini per {person_id}\")"
   ],
   "id": "49baff0b179a5256"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Calcolo delle performance sui dati clean",
   "id": "e62ef6c247a3e246"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "evaluate_performance(device, NN1)",
   "id": "a4908267f87d285c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
